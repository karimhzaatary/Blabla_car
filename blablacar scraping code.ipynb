{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import csv\n",
    "import re\n",
    "import time \n",
    "import pandas as pd \n",
    "driver = webdriver.Chrome()\n",
    "destination_list = ['Lyon, France']#, 'Nice, France','Bordeaux,France','Marseille,France','Lille,France','Strasbourg,France','Nantes,France','Toulouse,France','Amsterdam,Pays-Bas','Genève, Suisse','Barcelona,Espagne','Brussels, Belgique','Vichy, France','Berlin,Allemagne','Franktfurt,Allemagne']\n",
    "csv_file=open('Blablacar.csv','a',encoding='utf-8')\n",
    "writer=csv.writer(csv_file)\n",
    "\n",
    "\n",
    "\n",
    "for dest in destination_list:\n",
    "    driver.get(\"https://www.blablacar.fr/\")\n",
    "    from_box = driver.find_element_by_id(\"search_from_name\")\n",
    "    to_box = driver.find_element_by_id(\"search_to_name\")\n",
    "    from_box.send_keys('Paris, France')\n",
    "    to_box.send_keys(dest)\n",
    "    submit_button = driver.find_element_by_xpath('//button[@type=\"submit\"]')\n",
    "    submit_button.click()\n",
    "    #SCROLL_PAUSE_TIME = 3\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return window.scrollY\")\n",
    "   \n",
    "       \n",
    "    while True:\n",
    "        SCROLL_PAUSE_TIME = 3\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, window.scrollY+1000)\")\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return window.scrollY\")\n",
    "        if (new_height == last_height):\n",
    "            break\n",
    "        last_height = new_height\n",
    "        \n",
    "    tag_List=driver.find_elements_by_xpath('//li[@itemtype=\"http://schema.org/Event\"]')\n",
    "    Link2=[]\n",
    "    d={}\n",
    "    \n",
    "    d['destination']=[]\n",
    "    d['departure_time'] = []\n",
    "    d['arrival_time'] = []\n",
    "    d['price']=[]\n",
    "    d['picture']=[]\n",
    "    d['n_views']=[]\n",
    "    d['n_places']=[]\n",
    "    d['driver_age']=[]\n",
    "    d['driver_name']=[]\n",
    "    d['n_seats']=[]\n",
    "    d['Trip_Review']=[]\n",
    "    d['n_reviews']=[]\n",
    "    d['conduite']=[]\n",
    "    d['smoking']=[]\n",
    "    d['pets']=[]\n",
    "    d['n_annoucements']=[]\n",
    "    d['ID_verified']=[]\n",
    "    d['telephone']=[]\n",
    "    d['n_facebook']=[]\n",
    "    d['telephone']=[]\n",
    "    d['email']=[]\n",
    "    d['gender']=[]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for item in tag_List:\n",
    "        times = item.find_elements_by_xpath('.//time')\n",
    "        departure_time=times[0].get_attribute(\"datetime\")\n",
    "        arrival_time=times[1].get_attribute(\"datetime\")\n",
    "        d['departure_time'].append(departure_time)\n",
    "        d['arrival_time'].append(arrival_time)\n",
    "        d['destination'].append(dest)\n",
    "        \n",
    "        Link2.append(item.find_element_by_xpath('.//a').get_attribute(\"href\"))\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    for url in Link2:\n",
    "        driver.get(url)\n",
    "        #scraping for price:\n",
    "        try:\n",
    "            price=driver.find_element_by_xpath('.//span[@class=\"u-right u-textBold u-darkGray size30 padding-right\"]').text\n",
    "        except:\n",
    "            price=\"NA\"\n",
    "        d['price'].append(price)\n",
    "        \n",
    "        #scraping for picture:\n",
    "        try:\n",
    "            picture0=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-picture\"]')\n",
    "            picture1=picture0.find_element_by_xpath('.//img').get_attribute(\"src\")\n",
    "            b=picture1.find(\"avatar\")\n",
    "            if b!=-1:\n",
    "                picture=\"picture not available\"\n",
    "            elif b==-1:\n",
    "                picture=\"picture available\"\n",
    "        except:\n",
    "            picture=\"NA\"\n",
    "        d['picture'].append(picture)\n",
    "        \n",
    "        # scraping for number of views and printed date:\n",
    "        try:\n",
    "            n_views=driver.find_element_by_xpath('.//span[@class=\"u-cell\"]').text.stip\n",
    "        except:\n",
    "            n_views=\"NA\"\n",
    "        d['n_views'].append(n_views)\n",
    "        \n",
    "        # scrap for number of remianing seats\n",
    "        try:\n",
    "            remaining_0=driver.find_element_by_xpath(('.//div[@class=\"Booking-occupancy Block-section\"]'))\n",
    "            remaining=remaining_0.find_element_by_xpath('.//div[@class=\"padding-top\"]')\n",
    "            remaining_places=remaining.find_element_by_xpath('.//span[@class=\"u-textBold u-darkGray size20\"]').text\n",
    "\n",
    "        except:\n",
    "            remaining_places=0\n",
    "        d['n_places'].append(remaining_places)\n",
    "        \n",
    "        # scrap for total number of seats:\n",
    "        try:\n",
    "            seats2=driver.find_element_by_xpath('.//ul[@class=\"u-reset\"]')\n",
    "            seats1=seat.find_elements_by_xpath('.//li[@class=\"Booking-occupant\"]')\n",
    "            n_seats=len(seats1)\n",
    "        except:\n",
    "            n_seats=\"NA\"\n",
    "        d['n_seats'].append(n_seats)\n",
    "            \n",
    "\n",
    "            # scrap for driver age & driver name\n",
    "        try:\n",
    "            block_age=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-infosBlock\"]')\n",
    "            \n",
    "            age=block_age.find_element_by_xpath('.//div[@class=\"ProfileCard-info\"]').text.strip()\n",
    "            block_name=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-infosBlock\"]')\n",
    "            block_name1=block_name.find_element_by_xpath('.//h4[@class=\"ProfileCard-info ProfileCard-info--name u-truncate\"]')\n",
    "            name=block_name1.find_element_by_xpath('.//a[@rel=\"nofollow\"]').text\n",
    "        except:\n",
    "            age=\"NA\"\n",
    "        d['driver_age'].append(age)\n",
    "        d['driver_name'].append(name)\n",
    "        \n",
    "        # scrap for trip rating (numerical review)\n",
    "        try:\n",
    "            general_review=driver.find_element_by_xpath('.//p[@class=\"ratings-container\"]')\n",
    "            numerical_review=general_review.find_element_by_xpath('.//span[@class=\"u-textBold u-darkGray\"]').text\n",
    "            \n",
    "        except:\n",
    "            numerical_review=\"NA\"\n",
    "        d['Trip_Review'].append(numerical_review)\n",
    "\n",
    "            # scrap for trip rating (number of  review)\n",
    "        try:\n",
    "            general_review=driver.find_element_by_xpath('.//p[@class=\"ratings-container\"]')\n",
    "            number_of_reviews=general_review.find_element_by_xpath('.//span[@class=\"u-gray\"]').text\n",
    "        except:\n",
    "            number_of_reviews=\"NA\"\n",
    "        d['n_reviews'].append(number_of_reviews)\n",
    "\n",
    "\n",
    "\n",
    "            #scrap driving rating \n",
    "        try:\n",
    "            block_conduite=driver.find_element_by_xpath('.//div[@class=\"Block-section\"]')\n",
    "            profile=block_conduite.find_element_by_xpath('.//div[@class=\"ProfileCard\"]')\n",
    "            conduite=profile.find_element_by_xpath('.//div[@class=\"ProfileCard-row\"][2]').text.strip()\n",
    "        except:\n",
    "            conduite=\"NA\"\n",
    "        d['conduite'].append(conduite)\n",
    "        \n",
    "        #scrap for smoking permition\n",
    "        try:\n",
    "            regulations=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-row u-clearfix\"]')\n",
    "            smoking=regulations.find_element_by_xpath('.//span[@class=\"no-smoking prefs tip\"]').get_attribute(\"oldtitle\")\n",
    "            if smoking==\"La cigarette me dérange.\":\n",
    "                smoking=\"smoking not allowed\"\n",
    "            if smoking==\"La cigarette ne me dérange pas.\":\n",
    "                smoking==\"smoking allowed\"\n",
    "        except:  \n",
    "            smoking=\"smoking allowed\"\n",
    "        d['smoking'].append(smoking)\n",
    "        \n",
    "        \n",
    "            # scrap for pets acceptable \n",
    "        try:\n",
    "            regulations=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-row u-clearfix\"]')\n",
    "            pets=regulations.find_element_by_xpath('.//span[@class=\"no-pet prefs tip\"]').get_attribute(\"oldtitle\")\n",
    "            if pets==\"Je n'ai rien contre les animaux.\":\n",
    "                pets=\"pets allowed\"\n",
    "            if pets==\"Je ne veux pas voyager avec un animal.\":\n",
    "                pets=\"pets not allowed\"\n",
    "        except:\n",
    "\n",
    "            pets=\"pets allowed\"\n",
    "\n",
    "        d['pets'].append(pets)\n",
    "        \n",
    "        \n",
    "        \n",
    "            #scrap for number of annoucements\n",
    "        try:\n",
    "            n_annoucements0=driver.find_element_by_xpath('.//div[@class=\"Block-section\"]')\n",
    "            n_annoucements1=n_annoucements0.find_element_by_xpath('.//ul[@class=\"main-column-list u-reset\"]')\n",
    "            n_annoucements= n_annoucements1.find_element_by_xpath('.//li').text\n",
    "        except:\n",
    "            n_annoucements=\"NA\"\n",
    "        \n",
    "        \n",
    "        d['n_annoucements'].append(n_annoucements)\n",
    "        \n",
    "           #scrap identity card\n",
    "            \n",
    "        try:\n",
    "            verification_1=driver.find_element_by_xpath('.//div[@class=\"ProfileCard-infosBlock\"]')\n",
    "            liscense=verification_1.find_element_by_xpath('.//div[@class=\"ProfileCard-info u-blue\"]').text\n",
    "            a=liscense.find(\"Pièce d'identité vérifiée\")\n",
    "            if (a!=-1):\n",
    "                ID_verified=True\n",
    "            elif (a==-1):\n",
    "                 ID_verified=False\n",
    "        except:\n",
    "            ID_verified=False\n",
    "        \n",
    "        d['ID_verified'].append(ID_verified)\n",
    "        \n",
    "        #scrap to check telephone verfication\n",
    "        try:\n",
    "            block_telephone=driver.find_element_by_xpath('.//div[@class=\"Block-section\"]')\n",
    "            element=block_telephone.find_element_by_xpath('//ul[@class=\"main-column-list verification-list unstyled\"]')\n",
    "            telephone1=element.find_element_by_xpath('//li[1]/span[@class=\"u-alignMiddle u-green bold tip\"]').text.strip()\n",
    "            if telephone1==\"Téléphone vérifié\":\n",
    "                telephone=\" telephone available\"\n",
    "            else:\n",
    "                telephone=\" telephone not available\"\n",
    "                \n",
    "            \n",
    "        except:\n",
    "            telephone=\"telephone not available\"\n",
    "        \n",
    "        d['telephone'].append(telephone)\n",
    "        #scrap to check email verification\n",
    "        try:\n",
    "            block_email=driver.find_element_by_xpath('.//div[@class=\"Block-section\"]')\n",
    "            element_1=driver.find_element_by_xpath('.//ul[@class=\"main-column-list verification-list unstyled\"]')\n",
    "            email_2=element_1.find_element_by_xpath('.//li[2]/span').get_attribute(\"oldtitle\")\n",
    "            email_3=email_2.find(\"vérifié\")\n",
    "            if (email_3!=-1):\n",
    "                email= \"email available\"\n",
    "                \n",
    "        except:\n",
    "            email=\"email not available\"\n",
    "        \n",
    "        d['email'].append(email)\n",
    "\n",
    "            # scrap number of facebook freinds for drivers\n",
    "        try:\n",
    "            block_1=driver.find_element_by_xpath('.//div[@class=\"Block-section\"]')\n",
    "            block_2=block_1.find_elment_by_xpath('.//ul[class=\"main-column-list verification-list unstyled\"]')\n",
    "            n_facebook=block_2.find_element_by_xpath('.//li[3]/span[class=\"u-alignMiddle u-green bold\"]').text\n",
    "        except:\n",
    "             n_facebook=0\n",
    "        \n",
    "        d['n_facebook'].append(n_facebook)\n",
    "        \n",
    "        #try:\n",
    "           # gender=driver.find_element_by_xpath('.//use').get_attribute(\"href\")\n",
    "           # if gender==\"#icon-avatar-driver-m\":\n",
    "              #  gender = \"male\"\n",
    "           # if gender==\"#icon-avatar-driver-f\":\n",
    "              #  gender= \"female\"\n",
    "        #except:\n",
    "           # gender=\"not specified\"\n",
    "        \n",
    "        #d['gender'].append(gender)\n",
    "        #writer.writerow(d.keys())\n",
    "        writer.writerow(d.values()) \n",
    "        \n",
    "        \n",
    "keys = list(d.keys())\n",
    "values = list(d.values())\n",
    "data = pd.DataFrame({keys[0]:values[0],keys[1]:values[1],keys[2]:values[2],keys[3]:values[3],keys[4]:values[4],keys[5]:values[5],keys[6]:values[6],keys[7]:values[7],keys[8]:values[8],keys[9]:values[9],keys[10]:values[10],keys[11]:values[11],keys[12]:values[12],keys[13]:values[13],keys[14]:values[14],keys[15]:values[15],keys[16]:values[16],keys[17]:values[17],keys[18]:values[18],keys[19]:values[19]})\n",
    "\n",
    "data.to_csv('Blablacar.csv',index=False)      \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "           \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(d.keys())\n",
    "values = list(d.values())\n",
    "data = pd.DataFrame({keys[0]:values[0],keys[1]:values[1],keys[2]:values[2],keys[3]:values[3],keys[4]:values[4],keys[5]:values[5],keys[6]:values[6],keys[7]:values[7],keys[8]:values[8],keys[9]:values[9],keys[10]:values[10],keys[11]:values[11],keys[12]:values[12],keys[13]:values[13],keys[14]:values[14],keys[15]:values[15],keys[16]:values[16],keys[17]:values[17],keys[18]:values[18],keys[19]:values[19]})\n",
    "\n",
    "data.to_csv('Blablacar.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
